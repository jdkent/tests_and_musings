{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __**Running Freesurfer on Argon HPC**__\n",
    "\n",
    "\n",
    "This guide will cover how we will perform a longitudinal analysis using freesurfer utilizing our university's computing resources. \n",
    "\n",
    "__Resources__\n",
    "\n",
    "We will be talking about multiple resources not directly related to neuroimaging:\n",
    "\n",
    "-  [Docker](https://www.docker.com/): Provides a way to make/run software with complex dependencies into a standalone independent container (think executable file)\n",
    "\n",
    "\n",
    "-  [Singularity](http://singularity.lbl.gov/index.html): Similar to Docker, but does not require administrator privledges to run the standalone software; this means we can use it on the cluster where users do not have administrator privledges\n",
    "\n",
    "\n",
    "-  [HPC-Argon](https://wiki.uiowa.edu/display/hpcdocs/Argon+Cluster): A collection (cluster) of fancy computers that can chug through a bunch of data faster and more intelligently then the computers in our lab.\n",
    "\n",
    "And a couple resources that are related to neuroimaging:\n",
    "\n",
    "-  [FreeSurfer](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3685476/): The software workhorse designed to perform longitudinal structural analysis\n",
    "\n",
    "-  [Brain Imaging Data Structure (BIDS)](http://bids.neuroimaging.io/): The organizational principles our data must follow\n",
    "\n",
    "-  [BIDS-Apps](http://bids-apps.neuroimaging.io/), specifically the [FreeSurfer BIDS-App](https://github.com/BIDS-Apps/freesurfer): This provides the means to package the freesurfer software into a docker and/or singularity container that we can run anywhere.\n",
    "\n",
    "\n",
    "__Assumptions__\n",
    "\n",
    "This tutorial assumes:\n",
    "\n",
    "1. You have an Argon account\n",
    "2. You have access to your data via Argon\n",
    "3. Your data are organized in accordance to the BIDS standard\n",
    "3. The Singularity container you are using already has been made.\n",
    "4. You are using either Mac OSX or Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Login to Argon\n",
    "Open up your [terminal](http://linuxcommand.org/) and type the following, replacing *hawkid* with your hawkid\n",
    "\n",
    "__Generic__\n",
    "\n",
    "```bash\n",
    "ssh hawkid@argon.hpc.uiowa.edu\n",
    "```\n",
    "\n",
    "__Example__\n",
    "\n",
    "```bash\n",
    "ssh jdkent@argon.hpc.uiowa.edu\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Navigate to the correct Project Directory\n",
    "\n",
    "In Argon, all shares (places where we store data) are located under the directory `/Shared`. So we will navigate to the correct project directory starting from there\n",
    "\n",
    "```bash\n",
    "cd /Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/code\n",
    "```\n",
    "\n",
    "The above `code` directory will be where we make our *jobs* that we submit to the Argon cluster using our singularity container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Appropiate Directories\n",
    "In the code directory we will make a sub-directory (and several sub-sub-directories):\n",
    "\n",
    "sub-directory\n",
    "-  freesurfer_long: where we keep job files and related output in relation to freesurfer\n",
    "\n",
    "sub-sub-directories\n",
    "-  jobs: where we store the job files that we will submit to the Argon cluster\n",
    "-  err: where the error output will go in case something goes wrong with a job\n",
    "-  out: where the regular output will go from submitting the job\n",
    "\n",
    "Assuming we are in the code directory, we will make the sub-directory and sub-sub-directories with the following command\n",
    "\n",
    "```bash\n",
    "mkdir -p freesurfer_long/{jobs,out,err}\n",
    "```\n",
    "\n",
    "__EDIT__:\n",
    "we also need to make one more directory for the output of freesurfer in `/Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/`\n",
    "\n",
    "```bash\n",
    "mkdir /Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/freesurfer_long\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up a Template Job File\n",
    "Now that all the directories are in place we need to make a template job file. From this file, we will derive the individual subject job files we will submit to the Argon cluster.\n",
    "\n",
    "First we cd into the jobs directory:\n",
    "```bash\n",
    "cd ./freesurfer_long/jobs\n",
    "```\n",
    "\n",
    "Then we make a blank file:\n",
    "```bash\n",
    "touch TEMPLATE_freesurfer_long.job\n",
    "```\n",
    "\n",
    "Then we open the blank file so that we can write in it:\n",
    "```bash\n",
    "nano TEMPLATE_freesurfer_long.job\n",
    "```\n",
    "\n",
    "Then we would write something like the following into the blank file:\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "#$ -pe smp 16\n",
    "#$ -q UI\n",
    "#$ -m bea\n",
    "#$ -M james-kent@uiowa.edu\n",
    "#$ -o /Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/code/freesurfer_long/out\n",
    "#$ -e /Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/code/freesurfer_long/err\n",
    "OMP_NUM_THREADS=10\n",
    "singularity run -H ${HOME}/singularity_home -B /Shared/vosslabhpc:/mnt \\\n",
    "/Shared/vosslabhpc/UniversalSoftware/SingularityContainers/jdkent_freesurfer-2017-11-01-51dcee798e77.img \\\n",
    "/mnt/Projects/PACR-AD/Imaging/BIDS /mnt/Projects/PACR-AD/Imaging/BIDS/derivatives/freesurfer_long \\\n",
    "participant --participant_label SUBJECT \\\n",
    "--n_cpus 16 --skip_bids_validator \\\n",
    "--stages all --multiple_session longitudinal --license_file /mnt/UniversalSoftware/freesurfer_license.txt\n",
    "```\n",
    "\n",
    "__Explanation__\n",
    "\n",
    "To understand what's going on above the `singularity run ...` command, please see [basic job submission](https://wiki.uiowa.edu/display/hpcdocs/Basic+Job+Submission), and [advanced job submission](https://wiki.uiowa.edu/display/hpcdocs/Advanced+Job+Submission)\n",
    "\n",
    "I'll briefly describe the `-H` and `-B` options displayed after `singularity run`\n",
    "-  `-H`, this specifies what singularity will treat as the `$HOME` directory. Since Singularity essentially operates on top of your existing environment instead of completely separately (as docker does), sometimes default settings in your regular `$HOME` directory can override the settings in the singularity container. To avoid this conflict, I just make a new empty directory for Singularity to operate in.\n",
    "\n",
    "-  `-B`, The singularity container, however, does not have access to the all folders on our system, so this option explicitly binds where are data are to the singularity container so that freesurfer software can access and process the data.\n",
    "\n",
    "For the options specified after the singularity container (`/Shared/vosslabhpc/UniversalSoftware/SingularityContainers/jdkent_freesurfer-2017-11-01-51dcee798e77.img`), I'll refer you back to the [freesurfer BIDS-App page](https://github.com/BIDS-Apps/freesurfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate all the subject specific job files\n",
    "In the Template file you may have noticed the keyword __SUBJECT__ specified after the option `--participant-label`. To generate all the subject specific files we will use [sed](http://www.grymoire.com/Unix/Sed.html) to replace __SUBJECT__ with our specific participant labels (e.g. ControlGE140).\n",
    "\n",
    "Since we are lazy and don't want to write out our sed commands, we will call a script called generate_jobs.sh in a separate directory:\n",
    "```bash\n",
    "cd /Shared/vosslabhpc/Projects/PACR-AD/Imaging/BIDS/derivatives/code/misc\n",
    "```\n",
    "\n",
    "In this directory we will see a script called generate_jobs.sh and it contains the following code:\n",
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "function HelpMe\n",
    "{\n",
    "  echo \"Usage:\"\n",
    "  echo \"generate_jobs.sh -i SourceData -o CodeDir -t Template\"\n",
    "  echo \"SourceData = Directory containing source data\"\n",
    "  echo \"CodeDir = Output directory to place job scripts\"\n",
    "  echo \"Template = The template file containing the skeleton script\"\n",
    "  echo \"cont. the skeleton script should have SUBJECT in the place of participant label\"\n",
    "}\n",
    "\n",
    "\n",
    "while getopts \"i:o:t:h\" OPTION; do\n",
    "    case ${OPTION} in\n",
    "        i)\n",
    "            SourceData=${OPTARG}\n",
    "            ;;\n",
    "        o)\n",
    "            CodeDir=${OPTARG}\n",
    "            ;;\n",
    "        t)\n",
    "            Template=${OPTARG}\n",
    "            ;;\n",
    "        h)\n",
    "            HelpMe\n",
    "            exit 0\n",
    "            ;;\n",
    "    esac\n",
    "done\n",
    "\n",
    "SourceData=${SourceData:-\"unset\"}\n",
    "CodeDir=${CodeDir:-\"unset\"}\n",
    "Template=${Template:-\"unset\"}\n",
    "\n",
    "VarArray=(${SourceData} ${CodeDir} ${Template})\n",
    "if [[ ${VarArray[@]} =~ \"unset\" ]]; then\n",
    "    echo \"one of the mandatory variables is not set\"\n",
    "    HelpMe\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "#get suject list\n",
    "Subjects=$(find ${SourceData} -mindepth 1 -maxdepth 1 -name \"sub-*\" | xargs -I {} basename {} | awk -F\"-\" '{print $2}')\n",
    "\n",
    "#make job script based on Template\n",
    "for Subject in ${Subjects[@]}; do\n",
    "    sed -e \"s/SUBJECT/${Subject}/g\" ${Template} > ${CodeDir}/sub-${Subject}.job\n",
    "done\n",
    "```\n",
    "__Usage__\n",
    "\n",
    "Then calling the above (assuming we are in the `misc`) directory we will get the subject specific job files:\n",
    "\n",
    "```bash\n",
    "./generate_jobs.sh -i ../../../ -o ../freesurfer_long/jobs -t ../freesurfer_long/jobs/TEMPLATE_freesurfer_long.job\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Submit ONE of the generated jobs to the cluster\n",
    "It's always important to test if your job scripts work; if there's a systematic error in all the job files, you don't want to waste your time waiting for all of them to error out, so we will always test one job first.\n",
    "\n",
    "Go back to the jobs directory:\n",
    "```bash\n",
    "cd ../freesurfer_long/jobs\n",
    "```\n",
    "\n",
    "then submit ONE job to the cluster:\n",
    "```bash\n",
    "qsub sub-controlGE140.job\n",
    "```\n",
    "\n",
    "Then periodically check the status of the job, and the err/out files\n",
    "```bash\n",
    "# check status\n",
    "qstat -u jdkent\n",
    "# check err\n",
    "cat ../err/sub-controlGE140.e.*\n",
    "# check out\n",
    "cat ../out/sub-controlGE140.o.*\n",
    "```\n",
    "If all appears well after a while, then you can submit all the remaining jobs to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Submit the rest of the jobs\n",
    "Now we are ready to submit the rest of the jobs to the cluster.\n",
    "\n",
    "Since we already submitted `sub-controlGE140` to the cluster we will change their job file name so we don't accidently submit their file again.\n",
    "```bash\n",
    "mv sub-controlGE140.job test_sub-controlGE140.job\n",
    "```\n",
    "\n",
    "Then we use a `for loop` to submit the rest of the jobs to the cluster:\n",
    "```bash\n",
    "for job in sub-*.job; do qsub ${job}; done\n",
    "```\n",
    "\n",
    "Then you can check to see if everything is going well:\n",
    "```bash\n",
    "qstat -u jdkent\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONGRATS, FINISHED!\n",
    "Now you just wait forever for freesurfer to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
